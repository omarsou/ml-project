{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"Disaster_or_not.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"m5OXjTKNPNqo"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R4wAAY_wP7FI","executionInfo":{"status":"ok","timestamp":1603964132394,"user_tz":-60,"elapsed":2797,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["import numpy as np\n","import pandas as pd\n","import random\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import seaborn as sns\n","import transformers\n","from transformers import BertForSequenceClassification, BertTokenizerFast, AdamW\n","\n","# specify GPU\n","device = torch.device(\"cuda\")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"SSly6l18QJ12","executionInfo":{"status":"ok","timestamp":1603964134565,"user_tz":-60,"elapsed":496,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"f72778fd-244d-44f4-90ec-2a2035f785c6","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lfq8LOLVR5tH","executionInfo":{"status":"ok","timestamp":1603964135972,"user_tz":-60,"elapsed":453,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["data = pd.read_csv(\"/content/drive/My Drive/train.csv\")\n","data_valid = pd.read_csv(\"/content/drive/My Drive/test.csv\")"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zetl-c6qSe0K"},"source":["# Split into TRAIN / TEST set"]},{"cell_type":"code","metadata":{"id":"Ddt4ApMLSDTH","executionInfo":{"status":"ok","timestamp":1603964142376,"user_tz":-60,"elapsed":522,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"97d4a415-d3a9-47be-fdd4-21113f497b84","colab":{"base_uri":"https://localhost:8080/"}},"source":["train_text, test_text, train_labels, test_labels = train_test_split(data['text'], data['target'], \n","                                                                    random_state=66, \n","                                                                    test_size=0.1)\n","print(f\"Train has {len(train_text)} samples\")\n","print()\n","print(f\"Test has {len(test_text)} samples\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Train has 6851 samples\n","\n","Test has 762 samples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Tl-fXZ57TB0P"},"source":["# Import Tokenizer"]},{"cell_type":"code","metadata":{"id":"IytAAENgS12B","executionInfo":{"status":"ok","timestamp":1603964150105,"user_tz":-60,"elapsed":1089,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["# Load the BERT tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained('bert-large-uncased-whole-word-masking')"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Nx0wOHXTnqR"},"source":["# Tokenization"]},{"cell_type":"code","metadata":{"id":"8NOtR_1TTa4Y","executionInfo":{"status":"ok","timestamp":1603964162908,"user_tz":-60,"elapsed":1161,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"da8f2598-6ef0-4676-fd2e-622a8908ea19","colab":{"base_uri":"https://localhost:8080/"}},"source":["max_seq_len = 60\n","\n","\n","# tokenize and encode sequences in the training set\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the test set\n","tokens_test = tokenizer.batch_encode_plus(\n","    test_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"3LllXJwWTpZY"},"source":["## Converting to PyTorch Data Types (Tensor)"]},{"cell_type":"code","metadata":{"id":"33ZcAUmPTnCQ","executionInfo":{"status":"ok","timestamp":1603964335977,"user_tz":-60,"elapsed":769,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["# for train set\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","# for test set\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"re4Ro_eHTuID","executionInfo":{"status":"ok","timestamp":1603964337851,"user_tz":-60,"elapsed":517,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","#define a batch size\n","batch_size = 16\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_y)\n","\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","\n","# dataLoader for train set\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# wrap tensors\n","val_data = TensorDataset(test_seq, test_mask, test_y)\n","\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","\n","# dataLoader for validation set\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r4aUhYS5T_UW"},"source":["# Training our model"]},{"cell_type":"markdown","metadata":{"id":"uPTAkddyuChD"},"source":["## The Bert Model For Sequence Classification"]},{"cell_type":"code","metadata":{"id":"qAG6YAtMT-vn","executionInfo":{"status":"ok","timestamp":1603964357939,"user_tz":-60,"elapsed":17793,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"fabf90c1-9a44-4754-c5a9-323f8e0346ad","colab":{"base_uri":"https://localhost:8080/"}},"source":["model = BertForSequenceClassification.from_pretrained(\n","    \"bert-large-uncased-whole-word-masking\", \n","    num_labels = 2, # The number of output labels--2 for binary classification.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n","      (position_embeddings): Embedding(512, 1024)\n","      (token_type_embeddings): Embedding(2, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (12): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (13): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (14): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (15): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (16): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (17): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (18): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (19): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (20): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (21): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (22): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (23): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"-H1lPjf6uV9D"},"source":["## Some utils functions"]},{"cell_type":"code","metadata":{"id":"d8-xiqw4UIN8","executionInfo":{"status":"ok","timestamp":1603964428134,"user_tz":-60,"elapsed":906,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["# Save and Load Functions\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","def save_checkpoint(save_path, model, valid_loss):\n","\n","    if save_path == None:\n","        return\n","    \n","    state_dict = {'model_state_dict': model.state_dict(),\n","                  'valid_loss': valid_loss}\n","    \n","    torch.save(state_dict, save_path)\n","    print(f'Model saved to ==> {save_path}')\n","\n","def load_checkpoint(load_path, model):\n","    \n","    if load_path==None:\n","        return\n","    \n","    state_dict = torch.load(load_path, map_location=device)\n","    print(f'Model loaded from <== {load_path}')\n","    \n","    model.load_state_dict(state_dict['model_state_dict'])\n","    return state_dict['valid_loss']\n","\n","\n","def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n","\n","    if save_path == None:\n","        return\n","    \n","    state_dict = {'train_loss_list': train_loss_list,\n","                  'valid_loss_list': valid_loss_list,\n","                  'global_steps_list': global_steps_list}\n","    \n","    torch.save(state_dict, save_path)\n","    print(f'Model saved to ==> {save_path}')\n","\n","\n","def load_metrics(load_path):\n","\n","    if load_path==None:\n","        return\n","    \n","    state_dict = torch.load(load_path, map_location=device)\n","    print(f'Model loaded from <== {load_path}')\n","    \n","    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bz1hlme3ukSC"},"source":["## Optimizer & Learning Rate Scheduler"]},{"cell_type":"code","metadata":{"id":"FM0Caq2eX95r","executionInfo":{"status":"ok","timestamp":1603964433795,"user_tz":-60,"elapsed":701,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5,\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n","from transformers import get_linear_schedule_with_warmup\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 4\n","# Total number of training steps is number of batches * number of epochs.\n","total_steps = len(train_dataloader) * epochs\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-RIlikwUuyC0"},"source":["## Our training function (loop)"]},{"cell_type":"code","metadata":{"id":"6D0ovRv1ULRm","executionInfo":{"status":"ok","timestamp":1603965902904,"user_tz":-60,"elapsed":1302762,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"86a62fdc-58fd-4e1c-e89e-d7a7d44a55a9","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Training Function\n","\n","def train(model,\n","          optimizer,\n","          scheduler=scheduler,\n","          train_loader = train_dataloader,\n","          valid_loader = val_dataloader,\n","          num_epochs = epochs,\n","          file_path = None,\n","          best_valid_loss = float(\"Inf\")):\n","    \n","    # For reproductibility\n","    seed_val = 42\n","    random.seed(seed_val)\n","    np.random.seed(seed_val)\n","    torch.manual_seed(seed_val)\n","    torch.cuda.manual_seed_all(seed_val)\n","\n","    # initialize running values\n","    running_loss = 0.0\n","    valid_running_loss = 0.0\n","    global_step = 0\n","    eval_accuracy = 0\n","    train_loss_list = []\n","    valid_loss_list = []\n","    global_steps_list = []\n","\n","    # training loop\n","    model.train()\n","    for epoch in range(num_epochs):\n","      # iterate over batches\n","      for step,batch in enumerate(train_loader):\n","        # Unpack this training batch from our dataloader.\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a backward pass. \n","        # PyTorch doesn't do this automatically\n","        model.zero_grad()\n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # This will return the loss (rather than the model output) because we\n","        # have provided the `labels`.\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","        loss, _ = outputs\n","        \n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        running_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","      global_step += 1\n","\n","      # evaluation step\n","      model.eval()\n","      # Evaluate data for one epoch\n","      for batch in valid_loader:\n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # Telling the model not to compute or store gradients, saving memory and\n","        # speeding up validation\n","        with torch.no_grad():                    \n","          output = model(b_input_ids, \n","                         token_type_ids=None, \n","                         attention_mask=b_input_mask, \n","                         labels=b_labels)\n","          loss, _ = output\n","          valid_running_loss += loss.item()\n","\n","\n","          # Forward pass, calculate logit predictions.\n","          # This will return the logits rather than the loss because we have\n","          # not provided labels.\n","          # token_type_ids is the same as the \"segment ids\", which \n","          # differentiates sentence 1 and 2 in 2-sentence tasks.\n","          # The documentation for this `model` function is here: \n","          # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","          outputs = model(b_input_ids, \n","                          token_type_ids=None, \n","                          attention_mask=b_input_mask)\n","        \n","          # Get the \"logits\" output by the model. The \"logits\" are the output\n","          # values prior to applying an activation function like the softmax.\n","          logits = outputs[0]\n","          # Move logits and labels to CPU\n","          logits = logits.detach().cpu().numpy()\n","          label_ids = b_labels.to('cpu').numpy()\n","        \n","          # Calculate the accuracy for this batch of test sentences.\n","          tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        \n","          # Accumulate the total accuracy.\n","          eval_accuracy += tmp_eval_accuracy\n","      # evaluation\n","      average_train_loss = running_loss / len(train_loader)\n","      average_valid_loss = valid_running_loss / len(valid_loader)\n","      train_loss_list.append(average_train_loss)\n","      valid_loss_list.append(average_valid_loss)\n","      global_steps_list.append(global_step)\n","\n","      # resetting running values\n","      running_loss = 0.0                \n","      valid_running_loss = 0.0\n","      # Report the final accuracy for this validation run.\n","      print(f\"Validation Accuracy: {eval_accuracy/global_step}\")\n","      model.train()\n","\n","      # print progress\n","      print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {average_train_loss}, Valid Loss: {average_valid_loss}')\n","                \n","      # checkpoint\n","      if best_valid_loss > average_valid_loss:\n","        best_valid_loss = average_valid_loss\n","        save_checkpoint(file_path + '/' + 'model.pt', model, best_valid_loss)\n","        save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n","    \n","    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n","    print('Finished Training!')\n","\n","optimizer = AdamW(model.parameters(), lr=2e-5)\n","train(model=model, optimizer=optimizer, file_path=\"/content/drive/My Drive/\")"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 39.775\n","Epoch [1/4], Train Loss: 0.4494505514909615, Valid Loss: 0.45404368328551453\n","Model saved to ==> /content/drive/My Drive//model.pt\n","Model saved to ==> /content/drive/My Drive//metrics.pt\n","Validation Accuracy: 38.993750000000006\n","Epoch [2/4], Train Loss: 0.3715378373062416, Valid Loss: 0.5389387781421343\n","Validation Accuracy: 38.900000000000006\n","Epoch [3/4], Train Loss: 0.31741957341283905, Valid Loss: 0.5997336654302975\n","Validation Accuracy: 39.118750000000006\n","Epoch [4/4], Train Loss: 0.2672204338383181, Valid Loss: 0.5112070254981518\n","Model saved to ==> /content/drive/My Drive//metrics.pt\n","Finished Training!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RSJ1sf2hvbV3"},"source":["## Diagram of the training's evolution"]},{"cell_type":"code","metadata":{"id":"eG1pEFjFZsSC","executionInfo":{"status":"ok","timestamp":1603966030667,"user_tz":-60,"elapsed":604,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"a5513165-1ab4-493b-f1f2-f00b0a3e7aa9","colab":{"base_uri":"https://localhost:8080/","height":296}},"source":["import matplotlib.pyplot as plt\n","train_loss_list, valid_loss_list, global_steps_list = load_metrics( '/content/drive/My Drive/' \n","                                                                   + '/metrics.pt')\n","plt.plot(global_steps_list, train_loss_list, label='Train')\n","plt.plot(global_steps_list, valid_loss_list, label='Valid')\n","plt.xlabel('Global Steps')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show() "],"execution_count":16,"outputs":[{"output_type":"stream","text":["Model loaded from <== /content/drive/My Drive//metrics.pt\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"EDZbcu4ovnQR"},"source":["# Model Evaluation "]},{"cell_type":"code","metadata":{"id":"6EimVe67mJIR","executionInfo":{"status":"ok","timestamp":1603966090400,"user_tz":-60,"elapsed":51259,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"f1a5be08-1be3-440d-a03b-5d1a0be9efc0","colab":{"base_uri":"https://localhost:8080/","height":587}},"source":["# Evaluation Function\n","\n","def evaluate(model, test_loader):\n","    y_pred = []\n","    y_true = []\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for batch in test_loader:\n","          # Add batch to GPU\n","          batch = tuple(t.to(device) for t in batch)\n","          # Unpack the inputs from our dataloader\n","          b_input_ids, b_input_mask, b_labels = batch\n","          output = model(b_input_ids, \n","                          token_type_ids=None, \n","                          attention_mask=b_input_mask)\n","\n","          output = output[0]\n","          y_pred.extend(torch.argmax(output, 1).tolist())\n","          y_true.extend(b_labels.tolist())\n","    \n","    print('Classification Report:')\n","    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n","    \n","    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n","    ax= plt.subplot()\n","    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n","\n","    ax.set_title('Confusion Matrix')\n","\n","    ax.set_xlabel('Predicted Labels')\n","    ax.set_ylabel('True Labels')\n","\n","    ax.xaxis.set_ticklabels(['FAKE', 'REAL'])\n","    ax.yaxis.set_ticklabels(['FAKE', 'REAL'])\n","    \n","best_model = BertForSequenceClassification.from_pretrained(\n","    \"bert-large-uncased-whole-word-masking\").to(device)\n","\n","load_checkpoint('/content/drive/My Drive/' + '/model.pt', best_model)\n","\n","evaluate(best_model, val_dataloader)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["Model loaded from <== /content/drive/My Drive//model.pt\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1     0.8070    0.7846    0.7956       325\n","           0     0.8430    0.8604    0.8516       437\n","\n","    accuracy                         0.8281       762\n","   macro avg     0.8250    0.8225    0.8236       762\n","weighted avg     0.8277    0.8281    0.8278       762\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"G41_R8vLn6Qj","executionInfo":{"status":"ok","timestamp":1603966533221,"user_tz":-60,"elapsed":545,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"92f77c31-9416-4b16-985e-3f0558d5b3c8","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(\"The accuracy of the validation set is equal to\", float((255+376)/(255+376+61+70)*100))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["The accuracy of the validation set is equal to 82.80839895013123\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_polJYr_vsz5"},"source":["# Kaggle Submissions"]},{"cell_type":"code","metadata":{"id":"6K3v9qLCaMJJ","executionInfo":{"status":"ok","timestamp":1603966539276,"user_tz":-60,"elapsed":822,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"225e295c-02bb-46ec-b74e-2b48ed69053f","colab":{"base_uri":"https://localhost:8080/"}},"source":["from torch.utils.data import TensorDataset, DataLoader\n","tokens_kaggle = tokenizer.batch_encode_plus(\n","    data_valid['text'].tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False)\n","kaggle_seq = torch.tensor(tokens_kaggle['input_ids'])\n","kaggle_mask = torch.tensor(tokens_kaggle['attention_mask'])\n","# wrap tensors\n","kaggle_data = TensorDataset(kaggle_seq, kaggle_mask)\n","kaggle_dataloader = DataLoader(kaggle_data, batch_size=16)\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ONC_AyW4royJ","executionInfo":{"status":"ok","timestamp":1603966588292,"user_tz":-60,"elapsed":45827,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["pred = []\n","for batch in kaggle_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask = batch\n","  with torch.no_grad():\n","    preds_kaggle = best_model(b_input_ids, b_input_mask)\n","    preds_kaggle = preds_kaggle[0].detach().cpu().numpy()\n","    preds_ = np.argmax(preds_kaggle, axis = 1).tolist()\n","    pred += preds_"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"jfpPXulrcDXq","executionInfo":{"status":"ok","timestamp":1603966610275,"user_tz":-60,"elapsed":873,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"7ce8a2c3-7c2b-4e9d-b480-d77705b84d96","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["data_valid['target'] = pred\n","data_valid.head()"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Just happened a terrible car crash</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Heard about #earthquake is different cities, s...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>there is a forest fire at spot pond, geese are...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Apocalypse lighting. #Spokane #wildfires</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id keyword  ...                                               text target\n","0   0     NaN  ...                 Just happened a terrible car crash      1\n","1   2     NaN  ...  Heard about #earthquake is different cities, s...      1\n","2   3     NaN  ...  there is a forest fire at spot pond, geese are...      1\n","3   9     NaN  ...           Apocalypse lighting. #Spokane #wildfires      1\n","4  11     NaN  ...      Typhoon Soudelor kills 28 in China and Taiwan      1\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"9QEXAa43cOtb","executionInfo":{"status":"ok","timestamp":1603966620940,"user_tz":-60,"elapsed":516,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["data_to_csv = data_valid.drop(['text', 'keyword', 'location'], axis=1)\n","data_to_csv.to_csv('/content/drive/My Drive/sample_submissions_bert_v2.csv',index=False)"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oh61cW-wdPZx"},"source":["**The score is 0.833286\n"," which is better than the bag-of-words methods and the glove+bilstm one ...**"]}]}