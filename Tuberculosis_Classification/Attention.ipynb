{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Attention.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP96sqhx39u0zSNmfrxII8/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"wjaakJFZuYDA"},"source":["Implementation from https://github.com/kobiso/CBAM-keras"]},{"cell_type":"code","metadata":{"id":"CItMhIybjxVb","executionInfo":{"status":"ok","timestamp":1604851713956,"user_tz":-60,"elapsed":22443,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"e52b6c96-be04-4beb-a7c7-2b8bbe6641ee","colab":{"base_uri":"https://localhost:8080/"}},"source":["from keras import backend as K\n","from keras.activations import sigmoid\n","import numpy as np \n","import random\n","import pandas as pd\n","import os\n","import matplotlib.pyplot as plt\n","import cv2\n","from shutil import copyfile\n","import keras\n","from keras.layers import Flatten, Dense, Input, GlobalAveragePooling2D, \\\n","    GlobalMaxPooling2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, \\\n","    AveragePooling2D, Reshape, Permute, multiply, ZeroPadding2D, Dropout, LeakyReLU, \\\n","    Concatenate, Add, Lambda\n","from keras.models import Model, Sequential, load_model, model_from_json\n","from keras_preprocessing.image import ImageDataGenerator\n","from keras.optimizers import RMSprop, Adam\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","import tensorflow as tf\n","from keras.applications import VGG16 \n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from sklearn.preprocessing import OneHotEncoder\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","random.seed(34) # For reproductibility\n","np.random.seed(34)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4SYC4AsrmMuW"},"source":["# CBAM BLOCK"]},{"cell_type":"code","metadata":{"id":"7JtsujRij5Tu","executionInfo":{"status":"ok","timestamp":1604852863378,"user_tz":-60,"elapsed":580,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["def cbam_block(cbam_feature, ratio=8):\n","\t\"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n","\tAs described in https://arxiv.org/abs/1807.06521.\n","\t\"\"\"\n","\t\n","\tcbam_feature = channel_attention(cbam_feature, ratio)\n","\tcbam_feature = spatial_attention(cbam_feature)\n","\treturn cbam_feature\n","\n","def channel_attention(input_feature, ratio=8):\n","\t\n","\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n","\tchannel = input_feature.shape[channel_axis]\n","\t\n","\tshared_layer_one = Dense(channel//ratio,\n","\t\t\t\t\t\t\t activation='relu',\n","\t\t\t\t\t\t\t kernel_initializer='he_normal',\n","\t\t\t\t\t\t\t use_bias=True,\n","\t\t\t\t\t\t\t bias_initializer='zeros')\n","\tshared_layer_two = Dense(channel,\n","\t\t\t\t\t\t\t kernel_initializer='he_normal',\n","\t\t\t\t\t\t\t use_bias=True,\n","\t\t\t\t\t\t\t bias_initializer='zeros')\n","\t\n","\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n","\tavg_pool = Reshape((1,1,channel))(avg_pool)\n","\tassert avg_pool.shape[1:] == (1,1,channel)\n","\tavg_pool = shared_layer_one(avg_pool)\n","\tassert avg_pool.shape[1:] == (1,1,channel//ratio)\n","\tavg_pool = shared_layer_two(avg_pool)\n","\tassert avg_pool.shape[1:] == (1,1,channel)\n","\t\n","\tmax_pool = GlobalMaxPooling2D()(input_feature)\n","\tmax_pool = Reshape((1,1,channel))(max_pool)\n","\tassert max_pool.shape[1:] == (1,1,channel)\n","\tmax_pool = shared_layer_one(max_pool)\n","\tassert max_pool.shape[1:] == (1,1,channel//ratio)\n","\tmax_pool = shared_layer_two(max_pool)\n","\tassert max_pool.shape[1:] == (1,1,channel)\n","\t\n","\tcbam_feature = Add()([avg_pool,max_pool])\n","\tcbam_feature = Activation('sigmoid')(cbam_feature)\n","\t\n","\tif K.image_data_format() == \"channels_first\":\n","\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n","\t\n","\treturn multiply([input_feature, cbam_feature])\n","\n","def spatial_attention(input_feature):\n","\tkernel_size = 7\n","\t\n","\tif K.image_data_format() == \"channels_first\":\n","\t\tchannel = input_feature.shape[1]\n","\t\tcbam_feature = Permute((2,3,1))(input_feature)\n","\telse:\n","\t\tchannel = input_feature.shape[-1]\n","\t\tcbam_feature = input_feature\n","\t\n","\tavg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n","\tassert avg_pool.shape[-1] == 1\n","\tmax_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n","\tassert max_pool.shape[-1] == 1\n","\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n","\tassert concat.shape[-1] == 2\n","\tcbam_feature = Conv2D(filters = 1,\n","\t\t\t\t\tkernel_size=kernel_size,\n","\t\t\t\t\tstrides=1,\n","\t\t\t\t\tpadding='same',\n","\t\t\t\t\tactivation='sigmoid',\n","\t\t\t\t\tkernel_initializer='he_normal',\n","\t\t\t\t\tuse_bias=False)(concat)\t\n","\tassert cbam_feature.shape[-1] == 1\n","\t\n","\tif K.image_data_format() == \"channels_first\":\n","\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n","\t\t\n","\treturn multiply([input_feature, cbam_feature])"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IqjYceiGlpF3"},"source":["# Generate Data"]},{"cell_type":"code","metadata":{"id":"XyZmBmBUlqdD","executionInfo":{"status":"ok","timestamp":1604851942096,"user_tz":-60,"elapsed":221790,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"27522f59-c11e-489a-a6b5-ff7ad52a719d","colab":{"base_uri":"https://localhost:8080/"}},"source":["X_true = []\n","y_true = []\n","for image_path in os.listdir(\"/content/drive/My Drive/tuberculose/data/train/True/\"):\n","  img = cv2.imread(\"/content/drive/My Drive/tuberculose/data/train/True/\" + image_path)\n","  X_true.append(img)\n","  y_true.append(1)\n","X_false = []\n","y_false = []\n","for image_path in os.listdir(\"/content/drive/My Drive/tuberculose/data/train/False/\"):\n","  img = cv2.imread(\"/content/drive/My Drive/tuberculose/data/train/False/\" + image_path)\n","  X_false.append(img)\n","  y_false.append(0)\n","X_test = []\n","for image_path in os.listdir(\"/content/drive/My Drive/tuberculose/data/test/\"):\n","  img = cv2.imread(\"/content/drive/My Drive/tuberculose/data/test/\" + image_path)\n","  X_test.append(img)\n","\n","X = X_true + X_false\n","y = y_true + y_false\n","c = list(zip(X,y))\n","random.shuffle(c)\n","X, y = zip(*c)\n","print(f'{len(X)} images in the total training set')\n","print(f'{len(X_test)} images in the test set')\n","\n","# Hot Encode Label\n","lb = {1 : [0,1], 0 : [1,0]}\n","y_lb = [lb[t] for t in y]\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y_lb, test_size=0.1, random_state=42)\n","print(f'{len(X_train)} images in the train set')\n","print(f'{len(X_val)} images in the val set')\n","\n","y_train, y_val = np.einsum('kli->lik', np.array([y_train])), np.einsum('kli->lik',np.array([y_val]))\n","\n","def generate_predictions(predictions):\n","  probs = []\n","  for x in predictions:\n","    probs.append(x[1])\n","  return probs\n","\n","ID_test = [x.split('.')[0] for x in os.listdir(\"/content/drive/My Drive/tuberculose/data/test/\")]"],"execution_count":3,"outputs":[{"output_type":"stream","text":["718 images in the total training set\n","82 images in the test set\n","646 images in the train set\n","72 images in the val set\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vONsYzk4mDiG","executionInfo":{"status":"ok","timestamp":1604851986224,"user_tz":-60,"elapsed":12890,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["img_height, img_width = 256, 256\n","batch_size = 16 \n","\n","## Going to do also some data augmentation since we don't have many images\n","train_datagen = ImageDataGenerator(rescale=1./255,\n","                                       rotation_range=50,\n","                                       width_shift_range=0.2,\n","                                       height_shift_range=0.2,\n","                                       shear_range=0.25,\n","                                       zoom_range=0.1,\n","                                       channel_shift_range = 20,\n","                                       horizontal_flip = True ,\n","                                       vertical_flip = True )\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","\n","def resize(img):\n","  img_ = cv2.resize(img, (img_height, img_width), interpolation=cv2.INTER_AREA)\n","  return img_\n","\n","X_train_resized = np.array([resize(x) for x in X_train])\n","X_val_resized = np.array([resize(x) for x in X_val])\n","\n","train_datagen.fit(X_train_resized, augment=True)\n","val_datagen.fit(X_val_resized)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kS2MSKjwnjoX"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"p6AhMvEipXFz","executionInfo":{"status":"ok","timestamp":1604854416674,"user_tz":-60,"elapsed":3462,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["from keras.regularizers import l2\n","def resnet_layer(inputs,\n","                 num_filters=16,\n","                 kernel_size=3,\n","                 strides=1,\n","                 activation='relu',\n","                 batch_normalization=True,\n","                 conv_first=True):\n","    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n","    # Arguments\n","        inputs (tensor): input tensor from input image or previous layer\n","        num_filters (int): Conv2D number of filters\n","        kernel_size (int): Conv2D square kernel dimensions\n","        strides (int): Conv2D square stride dimensions\n","        activation (string): activation name\n","        batch_normalization (bool): whether to include batch normalization\n","        conv_first (bool): conv-bn-activation (True) or\n","            bn-activation-conv (False)\n","    # Returns\n","        x (tensor): tensor as input to the next layer\n","    \"\"\"\n","    conv = Conv2D(num_filters,\n","                  kernel_size=kernel_size,\n","                  strides=strides,\n","                  padding='same',\n","                  kernel_initializer='he_normal',\n","                  kernel_regularizer=l2(1e-4))\n","\n","    x = inputs\n","    if conv_first:\n","        x = conv(x)\n","        if batch_normalization:\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","    else:\n","        if batch_normalization:\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","        x = conv(x)\n","    return x\n","\n","depth = 32\n","num_filters = 16\n","num_res_blocks = int((depth - 2) / 6)\n","\n","inputs = Input(shape=(256, 256, 3))\n","x = resnet_layer(inputs=inputs)\n","# Instantiate the stack of residual units\n","for stack in range(3):\n","      for res_block in range(num_res_blocks):\n","          strides = 1\n","          if stack > 0 and res_block == 0:  # first layer but not first stack\n","              strides = 2  # downsample\n","          y = resnet_layer(inputs=x,\n","                             num_filters=num_filters,\n","                             strides=strides)\n","          y = resnet_layer(inputs=y,\n","                             num_filters=num_filters,\n","                             activation=None)\n","          if stack > 0 and res_block == 0:  # first layer but not first stack\n","              # linear projection residual shortcut connection to match\n","              # changed dims\n","              x = resnet_layer(inputs=x,\n","                                 num_filters=num_filters,\n","                                 kernel_size=1,\n","                                 strides=strides,\n","                                 activation=None,\n","                                 batch_normalization=False)\n","          # attention_module\n","          y = cbam_block(y)\n","          x = keras.layers.add([x, y])\n","          x = Activation('relu')(x)\n","      num_filters *= 2\n","\n","# Add classifier on top.\n","# v1 does not use BN after last shortcut connection-ReLU\n","x = AveragePooling2D(pool_size=8)(x)\n","x = Dense(512, activation='relu')(x)\n","x = Dropout(0.3)(x)\n","y = Flatten()(x)\n","outputs = Dense(2, activation='softmax',\n","                kernel_initializer='he_normal')(y)\n","\n","# Instantiate model.\n","model = Model(inputs=inputs, outputs=outputs)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"a76ElKHXr3YU"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1EKItkIor9gH","executionInfo":{"status":"ok","timestamp":1604853006692,"user_tz":-60,"elapsed":622,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["model.compile(loss='categorical_crossentropy',\n","              optimizer=Adam(lr=0.001),\n","              metrics=['acc'])"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"54blB-xBsYqT","executionInfo":{"status":"error","timestamp":1604854385983,"user_tz":-60,"elapsed":1299019,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"efe5785d-f309-4637-b854-02300c584f64","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["checkpoint = ModelCheckpoint(\"/content/drive/My Drive/tuberculose/xray_tuberculo_attention.h5\",\n","                             monitor=\"val_acc\",\n","                             mode=\"max\",\n","                             save_best_only = True,\n","                             verbose=1)\n","\n","#earlystop = EarlyStopping(monitor = 'val_loss', \n","                          #min_delta = 0, \n","                          #patience = 6,\n","                          #verbose = 1,\n","                          #restore_best_weights = True)\n","reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', min_delta=0.0001, cooldown=5, min_lr=0.0001)\n","# We put our call backs into a callback list\n","callbacks = [reduceLROnPlat, checkpoint]\n","\n","epochs = 100\n","nb_train = 646\n","nb_val = 72\n","history = model.fit_generator(train_datagen.flow(X_train_resized, y_train, batch_size=batch_size),\n","                                 steps_per_epoch=nb_train // batch_size,\n","                                 epochs=epochs,\n","                                 callbacks=callbacks,\n","                                 validation_data=val_datagen.flow(X_val_resized, y_val, batch_size=batch_size),\n","                                 validation_steps=nb_val // batch_size)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-13-f0460b3da0d4>:24: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.fit, which supports generators.\n","Epoch 1/100\n","40/40 [==============================] - ETA: 0s - loss: 1.2090 - acc: 0.5810\n","Epoch 00001: val_acc improved from -inf to 0.59375, saving model to /content/drive/My Drive/tuberculose/xray_tuberculo_attention.h5\n","40/40 [==============================] - 28s 690ms/step - loss: 1.2090 - acc: 0.5810 - val_loss: 0.9365 - val_acc: 0.5938\n","Epoch 2/100\n","40/40 [==============================] - ETA: 0s - loss: 0.8636 - acc: 0.6984\n","Epoch 00002: val_acc did not improve from 0.59375\n","40/40 [==============================] - 25s 617ms/step - loss: 0.8636 - acc: 0.6984 - val_loss: 0.9182 - val_acc: 0.5938\n","Epoch 3/100\n","40/40 [==============================] - ETA: 0s - loss: 0.9035 - acc: 0.6587\n","Epoch 00003: val_acc did not improve from 0.59375\n","40/40 [==============================] - 24s 611ms/step - loss: 0.9035 - acc: 0.6587 - val_loss: 0.9034 - val_acc: 0.5938\n","Epoch 4/100\n","40/40 [==============================] - ETA: 0s - loss: 0.8568 - acc: 0.6651\n","Epoch 00004: val_acc improved from 0.59375 to 0.75000, saving model to /content/drive/My Drive/tuberculose/xray_tuberculo_attention.h5\n","40/40 [==============================] - 25s 630ms/step - loss: 0.8568 - acc: 0.6651 - val_loss: 0.8852 - val_acc: 0.7500\n","Epoch 5/100\n","40/40 [==============================] - ETA: 0s - loss: 0.8324 - acc: 0.6921\n","Epoch 00005: val_acc did not improve from 0.75000\n","40/40 [==============================] - 24s 608ms/step - loss: 0.8324 - acc: 0.6921 - val_loss: 0.8413 - val_acc: 0.6094\n","Epoch 6/100\n","40/40 [==============================] - ETA: 0s - loss: 0.8449 - acc: 0.6714\n","Epoch 00006: val_acc did not improve from 0.75000\n","40/40 [==============================] - 24s 610ms/step - loss: 0.8449 - acc: 0.6714 - val_loss: 0.8974 - val_acc: 0.6094\n","Epoch 7/100\n","40/40 [==============================] - ETA: 0s - loss: 0.8221 - acc: 0.7095\n","Epoch 00007: val_acc did not improve from 0.75000\n","40/40 [==============================] - 24s 606ms/step - loss: 0.8221 - acc: 0.7095 - val_loss: 0.8721 - val_acc: 0.6406\n","Epoch 8/100\n","40/40 [==============================] - ETA: 0s - loss: 0.8334 - acc: 0.6937\n","Epoch 00008: val_acc did not improve from 0.75000\n","40/40 [==============================] - 24s 605ms/step - loss: 0.8334 - acc: 0.6937 - val_loss: 0.8957 - val_acc: 0.6562\n","Epoch 9/100\n","40/40 [==============================] - ETA: 0s - loss: 0.8535 - acc: 0.6778\n","Epoch 00009: val_acc did not improve from 0.75000\n","40/40 [==============================] - 24s 609ms/step - loss: 0.8535 - acc: 0.6778 - val_loss: 0.8357 - val_acc: 0.7344\n","Epoch 10/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7856 - acc: 0.7365\n","Epoch 00010: val_acc did not improve from 0.75000\n","40/40 [==============================] - 24s 608ms/step - loss: 0.7856 - acc: 0.7365 - val_loss: 0.7718 - val_acc: 0.7500\n","Epoch 11/100\n","40/40 [==============================] - ETA: 0s - loss: 0.8021 - acc: 0.7317\n","Epoch 00011: val_acc did not improve from 0.75000\n","40/40 [==============================] - 24s 609ms/step - loss: 0.8021 - acc: 0.7317 - val_loss: 0.7608 - val_acc: 0.7500\n","Epoch 12/100\n","40/40 [==============================] - ETA: 0s - loss: 0.8030 - acc: 0.7190\n","Epoch 00012: val_acc did not improve from 0.75000\n","40/40 [==============================] - 25s 617ms/step - loss: 0.8030 - acc: 0.7190 - val_loss: 0.7690 - val_acc: 0.7344\n","Epoch 13/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7714 - acc: 0.7460\n","Epoch 00013: val_acc did not improve from 0.75000\n","40/40 [==============================] - 24s 608ms/step - loss: 0.7714 - acc: 0.7460 - val_loss: 0.7827 - val_acc: 0.7188\n","Epoch 14/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7548 - acc: 0.7365\n","Epoch 00014: val_acc did not improve from 0.75000\n","40/40 [==============================] - 24s 608ms/step - loss: 0.7548 - acc: 0.7365 - val_loss: 0.8904 - val_acc: 0.7500\n","Epoch 15/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7803 - acc: 0.7127\n","Epoch 00015: val_acc did not improve from 0.75000\n","40/40 [==============================] - 24s 608ms/step - loss: 0.7803 - acc: 0.7127 - val_loss: 0.8262 - val_acc: 0.7344\n","Epoch 16/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7681 - acc: 0.7286\n","Epoch 00016: val_acc did not improve from 0.75000\n","40/40 [==============================] - 24s 607ms/step - loss: 0.7681 - acc: 0.7286 - val_loss: 1.5091 - val_acc: 0.3906\n","Epoch 17/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7537 - acc: 0.7286\n","Epoch 00017: val_acc improved from 0.75000 to 0.76562, saving model to /content/drive/My Drive/tuberculose/xray_tuberculo_attention.h5\n","40/40 [==============================] - 25s 630ms/step - loss: 0.7537 - acc: 0.7286 - val_loss: 0.6917 - val_acc: 0.7656\n","Epoch 18/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7656 - acc: 0.7381\n","Epoch 00018: val_acc did not improve from 0.76562\n","40/40 [==============================] - 24s 607ms/step - loss: 0.7656 - acc: 0.7381 - val_loss: 1.0887 - val_acc: 0.5938\n","Epoch 19/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7437 - acc: 0.7444\n","Epoch 00019: val_acc did not improve from 0.76562\n","40/40 [==============================] - 24s 608ms/step - loss: 0.7437 - acc: 0.7444 - val_loss: 0.7823 - val_acc: 0.7344\n","Epoch 20/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7508 - acc: 0.7270\n","Epoch 00020: val_acc did not improve from 0.76562\n","40/40 [==============================] - 24s 607ms/step - loss: 0.7508 - acc: 0.7270 - val_loss: 0.7865 - val_acc: 0.7344\n","Epoch 21/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7402 - acc: 0.7594\n","Epoch 00021: val_acc did not improve from 0.76562\n","40/40 [==============================] - 25s 615ms/step - loss: 0.7402 - acc: 0.7594 - val_loss: 1.1384 - val_acc: 0.4219\n","Epoch 22/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7439 - acc: 0.7381\n","Epoch 00022: val_acc did not improve from 0.76562\n","40/40 [==============================] - 24s 607ms/step - loss: 0.7439 - acc: 0.7381 - val_loss: 2.2469 - val_acc: 0.4375\n","Epoch 23/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7198 - acc: 0.7508\n","Epoch 00023: val_acc did not improve from 0.76562\n","40/40 [==============================] - 24s 607ms/step - loss: 0.7198 - acc: 0.7508 - val_loss: 1.4121 - val_acc: 0.3906\n","Epoch 24/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7301 - acc: 0.7254\n","Epoch 00024: val_acc did not improve from 0.76562\n","40/40 [==============================] - 24s 607ms/step - loss: 0.7301 - acc: 0.7254 - val_loss: 0.8084 - val_acc: 0.7344\n","Epoch 25/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7210 - acc: 0.7413\n","Epoch 00025: val_acc did not improve from 0.76562\n","40/40 [==============================] - 24s 606ms/step - loss: 0.7210 - acc: 0.7413 - val_loss: 0.7203 - val_acc: 0.7656\n","Epoch 26/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6970 - acc: 0.7508\n","Epoch 00026: val_acc did not improve from 0.76562\n","40/40 [==============================] - 24s 607ms/step - loss: 0.6970 - acc: 0.7508 - val_loss: 1.7083 - val_acc: 0.4219\n","Epoch 27/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7171 - acc: 0.7365\n","Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n","\n","Epoch 00027: val_acc did not improve from 0.76562\n","40/40 [==============================] - 24s 606ms/step - loss: 0.7171 - acc: 0.7365 - val_loss: 0.9724 - val_acc: 0.4375\n","Epoch 28/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7238 - acc: 0.7270\n","Epoch 00028: val_acc did not improve from 0.76562\n","40/40 [==============================] - 24s 606ms/step - loss: 0.7238 - acc: 0.7270 - val_loss: 0.9944 - val_acc: 0.4688\n","Epoch 29/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7325 - acc: 0.7476\n","Epoch 00029: val_acc did not improve from 0.76562\n","40/40 [==============================] - 24s 606ms/step - loss: 0.7325 - acc: 0.7476 - val_loss: 0.7626 - val_acc: 0.7656\n","Epoch 30/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7128 - acc: 0.7302\n","Epoch 00030: val_acc improved from 0.76562 to 0.81250, saving model to /content/drive/My Drive/tuberculose/xray_tuberculo_attention.h5\n","40/40 [==============================] - 25s 632ms/step - loss: 0.7128 - acc: 0.7302 - val_loss: 0.6461 - val_acc: 0.8125\n","Epoch 31/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7223 - acc: 0.7508\n","Epoch 00031: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 608ms/step - loss: 0.7223 - acc: 0.7508 - val_loss: 0.6857 - val_acc: 0.7500\n","Epoch 32/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7104 - acc: 0.7397\n","Epoch 00032: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 609ms/step - loss: 0.7104 - acc: 0.7397 - val_loss: 0.8313 - val_acc: 0.7344\n","Epoch 33/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6939 - acc: 0.7381\n","Epoch 00033: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 608ms/step - loss: 0.6939 - acc: 0.7381 - val_loss: 0.7135 - val_acc: 0.7812\n","Epoch 34/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6744 - acc: 0.7587\n","Epoch 00034: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 606ms/step - loss: 0.6744 - acc: 0.7587 - val_loss: 1.0263 - val_acc: 0.6250\n","Epoch 35/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7054 - acc: 0.7476\n","Epoch 00035: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 607ms/step - loss: 0.7054 - acc: 0.7476 - val_loss: 0.7043 - val_acc: 0.7656\n","Epoch 36/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6578 - acc: 0.7778\n","Epoch 00036: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 608ms/step - loss: 0.6578 - acc: 0.7778 - val_loss: 0.7555 - val_acc: 0.7500\n","Epoch 37/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6872 - acc: 0.7524\n","Epoch 00037: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 609ms/step - loss: 0.6872 - acc: 0.7524 - val_loss: 2.6677 - val_acc: 0.4062\n","Epoch 38/100\n","40/40 [==============================] - ETA: 0s - loss: 0.7005 - acc: 0.7270\n","Epoch 00038: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 607ms/step - loss: 0.7005 - acc: 0.7270 - val_loss: 1.0748 - val_acc: 0.4844\n","Epoch 39/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6773 - acc: 0.7444\n","Epoch 00039: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 608ms/step - loss: 0.6773 - acc: 0.7444 - val_loss: 0.8361 - val_acc: 0.7344\n","Epoch 40/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6816 - acc: 0.7429\n","Epoch 00040: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 608ms/step - loss: 0.6816 - acc: 0.7429 - val_loss: 2.2939 - val_acc: 0.5000\n","Epoch 41/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6557 - acc: 0.7746\n","Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n","\n","Epoch 00041: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 606ms/step - loss: 0.6557 - acc: 0.7746 - val_loss: 0.8706 - val_acc: 0.6094\n","Epoch 42/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6527 - acc: 0.7651\n","Epoch 00042: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 608ms/step - loss: 0.6527 - acc: 0.7651 - val_loss: 0.7914 - val_acc: 0.6406\n","Epoch 43/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6676 - acc: 0.7587\n","Epoch 00043: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 607ms/step - loss: 0.6676 - acc: 0.7587 - val_loss: 0.6816 - val_acc: 0.7656\n","Epoch 44/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6355 - acc: 0.7587\n","Epoch 00044: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 607ms/step - loss: 0.6355 - acc: 0.7587 - val_loss: 0.7102 - val_acc: 0.7031\n","Epoch 45/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6441 - acc: 0.7603\n","Epoch 00045: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 608ms/step - loss: 0.6441 - acc: 0.7603 - val_loss: 1.2407 - val_acc: 0.4375\n","Epoch 46/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6612 - acc: 0.7651\n","Epoch 00046: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 608ms/step - loss: 0.6612 - acc: 0.7651 - val_loss: 3.6053 - val_acc: 0.4062\n","Epoch 47/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6480 - acc: 0.7603\n","Epoch 00047: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 608ms/step - loss: 0.6480 - acc: 0.7603 - val_loss: 0.6694 - val_acc: 0.7656\n","Epoch 48/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6640 - acc: 0.7492\n","Epoch 00048: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 608ms/step - loss: 0.6640 - acc: 0.7492 - val_loss: 0.7159 - val_acc: 0.6250\n","Epoch 49/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6513 - acc: 0.7492\n","Epoch 00049: val_acc did not improve from 0.81250\n","40/40 [==============================] - 25s 617ms/step - loss: 0.6513 - acc: 0.7492 - val_loss: 1.0147 - val_acc: 0.5312\n","Epoch 50/100\n","40/40 [==============================] - ETA: 0s - loss: 0.6458 - acc: 0.7524\n","Epoch 00050: val_acc did not improve from 0.81250\n","40/40 [==============================] - 24s 607ms/step - loss: 0.6458 - acc: 0.7524 - val_loss: 2.3558 - val_acc: 0.5000\n","Epoch 51/100\n","26/40 [==================>...........] - ETA: 8s - loss: 0.6626 - acc: 0.7562"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-f0460b3da0d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                                  \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_resized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                                  validation_steps=nb_val // batch_size)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"1lQkdBDjxqD7","executionInfo":{"status":"ok","timestamp":1604854463182,"user_tz":-60,"elapsed":7024,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}}},"source":["model.load_weights(\"/content/drive/My Drive/tuberculose/xray_tuberculo_attention.h5\")\n","x_test_ = np.array([resize(x) for x in X_test])\n","gen = ImageDataGenerator(rescale=1./255)\n","gen.fit(x_test_)\n","predict = model.predict(gen.flow(x_test_, batch_size=1, shuffle=False))\n","proba = generate_predictions(predict)\n","sub = pd.DataFrame({'ID' : ID_test, 'LABEL' : proba})\n","sub.to_csv('/content/drive/My Drive/tuberculose/sub_high_attention.csv', index=False)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JQWsecHyydKf"},"source":["Score of 0.774 ... which is the lowest score I got."]},{"cell_type":"markdown","metadata":{"id":"B-9wSuXzuPfT"},"source":["@TODO : Try to implement attention with VGG16"]},{"cell_type":"code","metadata":{"id":"wrEnzdm1nkTN"},"source":["base_model = VGG16(input_shape =  (256, 256, 3), \n","                  include_top = False, weights = 'imagenet')"],"execution_count":null,"outputs":[]}]}